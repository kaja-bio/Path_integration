<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="description" content="Nolan Lab Path Integration">
  <link rel="icon" type="image/svg+xml" href="/assets/favicon.ico" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mapping the Brain (and braining the map)</title>
  <link rel="stylesheet" href="styles.css">
</head>

<body>
  <div class=head>
    <div class="header">The Neural Map</div>
  </div>
  <div class="subheader">Path Integration</div>
  <section id="introduction">
    <div class="paragraph">Humans, like all animals, have an innate sense of where we are in the world and where we are
      going. We use it everywhere - to walk home, to go to the grocery store, to walk to the bathroom in the middle of
      the night. </div>
    <div class="paragraph">How we navigate is largely dependent on what information is available to us. Among those is
      beaconing, a strategy where we use a distant object to navigate to - say, “Hey, there’s a neon sign here saying
      ‘Pub’” - that’s probably the entrance to the pub. But what if you don’t have those clues? 
    </div>
    <div class="paragraph">Sat you're out on a hike with your friends. You drive up to the base of a formidable
      mountain, put on your best smile as your far fitter friend sets off onto the hike that he <em>promised</em> was more of a 
      "light walk." With a heavy pack and groaning feet, you zigzag across the area from landmark to landmark, until you finally settle down in the campsite for what you hope to be a restful night of sleep. </div>
    <div class="paragraph"> <strong>Tragedy strikes!</strong> It's the middle of the night and you're woken up in what an optimist would call a
      'puddle', and anyone else might label 'a decidedly sizable body of water'.</div>
    <div class="paragraph"><em>So much for the guy on Facebook Marketplace promising that the tent was waterproof.</em></div>
    <div class="paragraph">You start a nighttime hike back to the car. You wish one of you had
      brought a headlamp at least - you can't use any landmarks to navigate. Despite that, you somehow manage to make it
      back in one piece, going straight from the campsite to the carpark without any of the diversions you had
      undertaken on the way there. How did you <em>do</em>> that?</div>
    <p></p>
    <main>
      <div class="container">
        <div id="gameCanvas1"></div>
      </div>
    </main>
    <div></div>
    <p></p>
    <div class="paragraph">Two types of sensory information are required to update where we think we are: Allothetic
      information we get from the outside environment, like that ‘Pub’ sign. Idiothetic information is generated by the
      body itself. For example, the brain signals responsible for walking to the pub also provide us with
      information about how far we’ve walked so far. Path integration uses these idiothetic cues to transverse the mental
      map in our head. For example, a mouse that is foraging and takes a long, winding trajectory towards its goal will
      have ‘calculated’ its displacement from its nest and can make a beeline safely back if it suddenly runs into a
      fox.

    </div>
    <div class="container">
      <img class="comic" src="./images/mouse_integration.png" alt="Mouse integrating">
    </div>
    <div class="paragraph">Why do we want to understand the neuroscience of path integration? </div>
    <div class="paragraph">
      Path integration can tell us about mechanisms behind animal biology, primarily homing behaviors in both
      vertebrates and invertebrates. In humans, it might lead to a better understanding of how we process and understand
      sensory information and the cognitive processes behind it. The algorithms that are elucidated from biological
      systems can be applied to mechanical systems, or even used in healthcare to understand ways to improve navigation
      aids for patients where navigation has been impaired, such as due to vision loss. Studying path integration is
      complicated by the fact that it’s only one part of the mechanism behind navigation. It’s an error-prone system,
      and so it works in combination with other information to create a path - for example, a mouse might use remembered
      landmarks, olfaction and even way-marking to navigate through an environment. Studying the neurons specifically
      involved in path integration therefore requires us to remove all other possibilities but using path integration.
      How do we do <em>that?</em></div>
    <div class="container">
      <img class="comic" src="./images/pi_exp_1.png" alt="Path integration experiment">
    </div>
    <div class="paragraph">We can use a virtual reality experiment. Mice run through a
      repeated corridor on a virtual reality track until there's a visual cue, such as yellow stripes. If they stop
      at the visual cue, they're given a treat. Once the mice have made the association that stopping at that specific
      point gets them a treat, the visual cue is removed and the mice are put back on the track. Despite the absence of the cue, the mice keep stopping inthe place where the visual cue <em>would have been</em>. They can't use any allothetic cues - they're constructing their ideas of their displacement purely using path integration mechanisms. </div>
    <div class="paragraph"> If there were no external cues for the mice to us, how did they know when to stop? One
      possibility was that they estimated the time it took for them to run and stopped when they ran the same amount of
      time; the researchers tested for this by changing the speed of the treadmill and investigating whether mice that
      ran faster would overshoot the reward zone. However, the mice didn't stop at the
      wrong place when they ran faster for a shorter period of time. If they weren't measuring the time, how did they know when to stop?
    <p></p>The mice were getting their information from a collection of self-motion cues. This includes
      something called proprioception, which is a sense of how your body is positioned, along with the vestibular system
      (your inner ear, which provides a sense of balance and awareness of our head and body in space) and motor
      efference. Over longer distances, the accuracy of this system drops without external input such as landmarks, as
      small errors start to accumulate and the mice start to stop further away from the reward zone.
    </div>
    <div class="paragraph"></div>
    <div class="container">
      <img class="comic" src="./images/pi_exp_2.png" alt="Path integration experiment">
    </div>
    <div class="paragraph">There are many specialised cell types involved in navigation. For the purpose of this
      website, let’s focus on three: place cells, grid cells, and head direction cells.
      <p></p>
      <div class="image-container">
        <img class="comic" src="./images/cell_types.png" alt="cell types">
        <div class="hover-textbox">
          <p>
            <strong>Grid cells</strong>
          <p>are place-modulated neurons located primarily in the entorhinal cortex that fire periodically in space,
            mapping a triangular grid across an environment. As an animal moves through space, grid cells fire to create
            hexagonal patterns that allow us to map this space. Again, a population of grid cells alone can encode a
            spatial map</p>
          <p></p>
          <p></p>
          <strong>Place cells</strong>
          <p> located in the hippocampus, fire when an animal enters a specific location in space. A population of place
            cells alone can encode a spatial map.
            .</p>
          <p></p>
          <p></p>
          <p></p>
          <strong>Head direction cells</strong>
          <p>are rimarily found in the postsubiculum, and provide directional information by preferentially firing in
            specific directions. A population of head direction cells can encode which direction you are facing in your
            spatial map.
          </p>
          </p>
          <p></p>
          <p>These cells potentially have uses outside of encoding physical space - their coding mechanism may be used
            for more general problem sets, such as cognitive mapping. Cognitive mapping refers to swapping out the
            three-dimensional world we interact with for a different, continuous dimension that represents an abstract
            concept. The same way we might encode the map of our room, we might use the hexagonal-firing properties of
            grid cells to represent, for example, conceptual spaces, such as hierarchically organizing ideas within our
            brain, or recording temporal sequences of events.</p>
        </div>
      </div>
      <!-- In the hi
ppocampal formation, we might find <strong>boundary cells</strong>; as with head direction cells, these
      boundary cells are relatively self-explanatory. These fire when a specific receptive field intersected an
      environmental boundary, dependent solely on location and not on the direction of the animal -->
    </div>
    <!-- <div class="paragraph">Path integration is computed by grid cells within the medial entorhinal cortex and downstream
      ‘readout’ cells. What we want to find out is <strong>how grid cells collect and store data about location and
        movement</strong>, and <strong>how this information is then transferred and ‘read’ by cells in the
        hippocampus</strong>. -->
    <!-- <p></p>Grid cells provide a good mechanism for path integration as they are context-independent codes of distance.
      New environments and new contexts will lead to new sensory inputs, and information coding for spatial
      representation must therefore be generalizable across these differing conditions. Grid cells are close to input
      about speed and head direction and connect in the MEC with the hippocampus, which is generally thought of as an
      area used for read-out and storage of information about location. Continuous attractor dynamics functions as a
      theoretical framework of grid cell encoding of spatial information, wherein grid cells receive and integrate
      self-motion information, firing in a hexagonal-grid pattern as the animal moves through space and generating bumps
      of activity that morphs in response to the animal’s location. The activities of different neurons work together
      dynamically to inhibit or excite each other.
    </div>
    <div class="paragraph">Grid cells provide a coordinate system for the brain - like looking at a graph and seeing
      that a certain point is at an x-coordinate and y-coordinate, which tells us information about that data point.
      Generally, neighbouring grid cells belong to the same <strong>module</strong> - they have the same orientation and
      scale. Activity of cells in different modules is combined to get the exact location of the animal, as reading out
      information from just one grid cell would give us only a vague estimate of our position. Grid cells must be
      anchored to salient features in an environment to allow for correct calculations of distance. While path
      integration is a process that doesn’t rely on environmental information to create this internal “map”, it
      accumulates errors over time, which need to be corrected by allothetic cues and information from border cells.
      <p></p>
      An interesting question that has been posed is the boundary problem: what happens when an animal moves past the
      boundaries of this two-dimensional internal map? A potential answer imagined the connected continuous attractor
      networks of grid cells as a torus. A torus is basically shaped like a donut - so the network is connected together
      in this circular manner to prevent the possibility of leaving the boundaries.
    </div>
  </section>
  <div class="container">
    <img class="comic" src="" alt="Insert donut comic">
  </div>
  <div class="paragraph">To summarise the model that we’ve touched upon so far, place cells in the hippocampus fire when
    you enter a location that is within their place field. But while place cells tell you your location, you need more
    information to make your way through the world - you need to know information such as your direction (which is
    decoded from head direction cells), and very importantly, how far you’ve travelled to get where you are (a
    displacement vector), for which we use grid cells within the entorhinal cortex. But how does your brain actually
    interpret this information? How is it able to look at these cells firing and work back from that to actually tell
    you your displacement vector?
  </div>
  <div class="paragraph">A proposed computational model depicts this readout mechanism as information from the grid
    phases inputting to a network, which outputs to a neuron that has a firing rate proportional to the displacement of
    the animal. Essentially the collective modules of grid cells output to an intermediate <strong>ramping</strong>
    cell. The word ramping is used because the cell firing profile looks like a ramp - it might be going up or going
    down as you reach a goal location, for example. </div>
  <div class=paragraph>Why use ramping profiles to encode information?
    If we had an infinite amount of cells, we could encode information in a discrete way. However, we're working with a
    limited (but still very large!) pool of neurons. While encoding positional estimate using discrete firing fields
    would require us to compare firing rates within a population, using a continuous ramping profile could give us that
    same information from just one neuron!</div>
  <div class=paragraph>Running the same experimental set-up on a virtual reality track </div> -->
    <footer>
      <p>Created by Kaja Kubickova 2023</p>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/phaser@3.60.0/dist/phaser-arcade-physics.min.js"></script>
    <script type="module" src="js/main.js"></script>
</body>

</html>